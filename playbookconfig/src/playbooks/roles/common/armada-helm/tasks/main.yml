---
#
# Copyright (c) 2020 Wind River Systems, Inc.
#
# SPDX-License-Identifier: Apache-2.0
#
# ROLE DESCRIPTION:
#   This role is to perform tasks that configure and launch containerized Armada.
#

# For the IPv6 system, the CIDR address should be changed to IPv6 to allow
# users from IPv6 address to access DB (ie. tiller running in container)
- block:
  - name: Update postgresql pg_hba.conf with IPv6 address if system is IPv6
    command: "{{ item }}"
    args:
      warn: false
    with_items:
      - "sed --follow-symlinks -i -e 's|0.0.0.0/0|::0/0|g' /etc/postgresql/pg_hba.conf"
      - "sed --follow-symlinks -i -e 's|0.0.0.0/32|::0/128|g' /etc/postgresql/pg_hba.conf"

  - name: Restart postgresql
    systemd:
      name: postgresql
      state: restarted
  when: (mode != 'upgrade_k8s_armada_helm' and
         ipv6_addressing is defined and ipv6_addressing != False)

- name: Get Helm SQL database password
  vars:
    script_content: |
      import keyring
      password = keyring.get_password("helmv2", "database")
      if not password:
          raise Exception("Helm database password not found.")
      print(password)
  shell: "{{ script_content }}"
  args:
    executable: /usr/bin/python
  register: helm_sql_database_password

- name: Set Armada overrides
  set_fact:
    helm_charts_url: "http://{{ controller_floating_address | ipwrap }}:{{ helm_repo_port }}/helm_charts"
    helm_sql_connection_address: "postgresql://admin-helmv2:{{ helm_sql_database_password.stdout }}@{{
                                  controller_floating_address | ipwrap }}:5432/helmv2?sslmode=disable"
    helm_sql_endpoint_ip: "{{ controller_floating_address | ipwrap }}"

- name: Configure and launch containerized Armada
  block:
  - block:
    - name: Add Helm repos
      command: /sbin/helm repo add "{{ item }}" "http://127.0.0.1:{{ helm_repo_port }}/helm_charts/{{ item }}" --debug
      with_items:
        - "{{ helm_repo_name_apps }}"
        - "{{ helm_repo_name_platform }}"

    - name: Update Helm repos
      command: /sbin/helm repo update --debug
    when: mode != 'upgrade_k8s_armada_helm'

  - name: Create Armada overrides
    template:
      src: "roles/common/armada-helm/templates/armada-overrides.yaml.j2"
      dest: "/tmp/armada-overrides.yaml"
    become_user: sysadmin

  - block:
    - name: Create namespace for Armada
      command: >
        kubectl create namespace {{ armada_namespace }}
      failed_when: false
      register: create_ns

    - name: Fail if creating namespace fails
      fail:
        msg: "Failed to create {{ armada_namespace }} namespace. Error: {{ create_ns.stderr }}"
      when: create_ns.rc is defined and create_ns.rc !=0 and
            create_ns.stderr is not search('AlreadyExists')

    # The following labels are used by pod security admission controller
    - name: Add pod security labels to the armada namespace
      command: kubectl --kubeconfig=/etc/kubernetes/admin.conf
               label --overwrite namespaces armada
               pod-security.kubernetes.io/audit-version=latest
               pod-security.kubernetes.io/enforce-version=latest
               pod-security.kubernetes.io/warn-version=latest
               pod-security.kubernetes.io/audit=privileged
               pod-security.kubernetes.io/enforce=privileged
               pod-security.kubernetes.io/warn=privileged

    # Retrieve local registry credentials if it's unknown
    - block:
      - name: Get local registry credentials
        vars:
          script_content: |
            import keyring
            password = keyring.get_password("sysinv", "services")
            if not password:
                raise Exception("Local registry password not found.")
            print(dict(username='sysinv', password=str(password)))
        shell: "{{ script_content }}"
        args:
          executable: /usr/bin/python
        register: local_registry_credentials_output

      - set_fact:
          local_registry_credentials: "{{ local_registry_credentials_output.stdout }}"
          local_registry: "registry.local:9001"
      when: local_registry_credentials is not defined

    - name: Check if secret exists
      command: kubectl -n {{ armada_namespace }} get secret {{ armada_secret_name }}
      failed_when: false
      register: armada_get_secret

    - name: Create secret if it doesn't exist
      command: >-
        kubectl -n {{ armada_namespace }} create secret docker-registry {{ armada_secret_name }}
        --docker-server={{ local_registry }}
        --docker-username={{ local_registry_credentials['username'] }}
        --docker-password={{ local_registry_credentials['password'] }}
      when: armada_get_secret.rc is defined and armada_get_secret.rc !=0 and
            armada_get_secret.stderr is search('NotFound')

    # Configure sane node label values that work with armada node selector
    - name: Create Armada node label
      command: >
        kubectl label node controller-0 armada=enabled --overwrite=true

    # To prevent helm-upload requiring sudo and a tty for password,
    # become the intended www user.
    - name: Upload Armada charts
      become_user: www
      command: >
        /usr/local/sbin/helm-upload stx-platform /opt/extracharts/armada-0.1.0.tgz

    - name: Update info of available charts from chart repos
      command: >
        /sbin/helm repo update --debug

    - name: Check if Armada revisions exists
      command: >-
        /sbin/helm status armada
        --namespace {{ armada_namespace }}
      failed_when: false
      register: armada_check

    # Before Armada upgrade/install check if nginx exists
    # and if so then check if pod and service are available
    # otherwise Armada install will fail
    - block:
      - name: Set nginx facts
        set_fact:
          nginx_prefix: "ic-nginx-ingress-ingress-nginx"

      - name: Get ingress validating webhook service name
        command: >-
          kubectl get validatingwebhookconfiguration
          -ojsonpath="{.webhooks[0].clientConfig.service.name}"
          {{ nginx_prefix }}-admission
        register: nginx_webhook_service
        ignore_errors: true

      - name: If on system restore mode, kill ingress validating webhook pod so it can be recreated
        shell: >-
          kubectl delete pod -n kube-system --force
          -l $(kubectl get service -n kube-system {{ nginx_webhook_service.stdout }}
          -o jsonpath="{.spec.selector}" | tr -d "{}\"" | tr ":" "=")
        when: mode == 'restore' and armada_check.rc == 0 and nginx_webhook_service.rc == 0

      - name: Check ingress validating webhook service and pod status
        shell: >-
          kubectl wait pod -n kube-system
          {%- if mode == 'restore' %}
          --field-selector spec.nodeName=controller-0
          {%- endif %}
          -l $(kubectl get service -n kube-system {{ nginx_webhook_service.stdout }}
          -o jsonpath="{.spec.selector}" | tr -d "{}\"" | tr ":" "=")
          --for=condition=Ready
        register: webhook_pod_status
        until: webhook_pod_status.rc == 0
        retries: 6
        delay: 10
        when: armada_check.rc == 0 and nginx_webhook_service.rc == 0

    - name: Uninstall Armada revisions
      command: >-
        /sbin/helm uninstall
        --namespace {{ armada_namespace }} armada
      when: armada_check.rc == 0

    - name: Launch Armada with Helm v3
      command: >-
        /sbin/helm upgrade --install armada stx-platform/armada
        --namespace {{ armada_namespace }}
        --values /tmp/armada-overrides.yaml
        --debug
    when: mode != 'upgrade_k8s_armada_helm'

  # For the armada upgrade during system upgrade, wait until
  # armada pod is in a ready state before marking it as successful.
  # This is needed as helm releases migration should be done
  # after tiller is running with SQL backend
  - name: Launch Armada with Helm v3 (Upgrade armada)
    command: >-
      /sbin/helm upgrade --install armada stx-platform/armada
      --namespace {{ armada_namespace }}
      --values /tmp/armada-overrides.yaml
      --wait
      --debug
    when: mode == "upgrade_k8s_armada_helm"

  become_user: sysadmin
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
    HOME: /home/sysadmin
