---
#
# Copyright (c) 2019-2023 Wind River Systems, Inc.
#
# SPDX-License-Identifier: Apache-2.0
#
# ROLE DESCRIPTION:
#   This role is to validate and save host (non secure) config.
#

- name: Fail if any of the configured registry keys is unknown
  fail:
    msg: "Unknown registry key: '{{ item }}'. Acceptable keys are {{ known_registry_keys|join(', ') }} "
  when: not item in known_registry_keys
  with_items: "{{ user_defined_registry_keys }}"

# error check the password section of docker registries
# check password parameters before trying to hide the password
# we need to do that here as opposed to with the other docker registry
# stuff because of the debug log statement.
# we need to do this all before the debug log statement to not log passwords.
- name: Check k8s_registry credentials
  fail:
    msg: "k8s registry username and password must both be specified or not at all"
  when: (docker_registries[default_k8s_registry.url].username is defined and
         docker_registries[default_k8s_registry.url].password is not defined) or
        (docker_registries[default_k8s_registry.url].username is not defined and
         docker_registries[default_k8s_registry.url].password is defined)

- name: Check gcr_registry credentials
  fail:
    msg: "gcr registry username and password must both be specified or not at all"
  when: (docker_registries[default_gcr_registry.url].username is defined and
         docker_registries[default_gcr_registry.url].password is not defined) or
        (docker_registries[default_gcr_registry.url].username is not defined and
         docker_registries[default_gcr_registry.url].password is defined)

- name: Check quay_registry credentials
  fail:
    msg: "quay registry username and password must both be specified or not at all"
  when: (docker_registries[default_quay_registry.url].username is defined and
         docker_registries[default_quay_registry.url].password is not defined) or
        (docker_registries[default_quay_registry.url].username is not defined and
         docker_registries[default_quay_registry.url].password is defined)

- name: Check docker_registry credentials
  fail:
    msg: "docker registry username and password must both be specified or not at all"
  when: (docker_registries[default_docker_registry.url].username is defined and
         docker_registries[default_docker_registry.url].password is not defined) or
        (docker_registries[default_docker_registry.url].username is not defined and
         docker_registries[default_docker_registry.url].password is defined)

- name: Check elastic_registry credentials
  fail:
    msg: "elastic registry username and password must both be specified or not at all"
  when: (docker_registries[default_elastic_registry.url].username is defined and
         docker_registries[default_elastic_registry.url].password is not defined) or
        (docker_registries[default_elastic_registry.url].username is not defined and
         docker_registries[default_elastic_registry.url].password is defined)

- name: Check ghcr_registry credentials
  fail:
    msg: "ghcr registry username and password must both be specified or not at all"
  when: (docker_registries[default_ghcr_registry.url].username is defined and
         docker_registries[default_ghcr_registry.url].password is not defined) or
        (docker_registries[default_ghcr_registry.url].username is not defined and
         docker_registries[default_ghcr_registry.url].password is defined)

- name: Check registryk8s_registry credentials
  fail:
    msg: "registryk8s registry username and password must both be specified or not at all"
  when: (docker_registries[default_registryk8s_registry.url].username is defined and
         docker_registries[default_registryk8s_registry.url].password is not defined) or
        (docker_registries[default_registryk8s_registry.url].username is not defined and
         docker_registries[default_registryk8s_registry.url].password is defined)

- name: Check icr_registry credentials
  fail:
    msg: "icr registry username and password must both be specified or not at all"
  when: (docker_registries[default_icr_registry.url].username is defined and
         docker_registries[default_icr_registry.url].password is not defined) or
        (docker_registries[default_icr_registry.url].username is not defined and
         docker_registries[default_icr_registry.url].password is defined)

- name: Check defaults registry credentials
  fail:
    msg: "defaults registry username and password must both be specified or not at all"
  when: docker_registries['defaults'] is defined and
        ((docker_registries['defaults'].username is defined and
         docker_registries['defaults'].password is not defined) or
        (docker_registries['defaults'].username is not defined and
         docker_registries['defaults'].password is defined))

# create a copy of docker_registries without passwords for debug logging
- set_fact:
    docker_registries_with_secrets: "{{ docker_registries }}"

- set_fact:
    docker_registries: "{{ docker_registries | combine(hide_pw, recursive=true) }}"
  vars:
    hide_pw: "{ '{{ item.key }}': { 'password': 'secret' } }"
  with_dict: "{{ docker_registries }}"
  no_log: true

- debug:
    msg:
      - System mode is {{ system_mode }}
      - Timezone is {{ timezone }}
      - Distributed Cloud Role is {{ distributed_cloud_role }}
      - Region name is {{ region_name }}
      - DNS servers is {{ dns_servers }}
      - PXE boot subnet is {{ pxeboot_subnet }}
      - Management subnet is {{ management_subnet }}
      - Cluster host subnet is {{ cluster_host_subnet }}
      - Cluster pod subnet is {{ cluster_pod_subnet }}
      - Cluster service subnet is {{ cluster_service_subnet }}
      - OAM subnet is {{ external_oam_subnet }}
      - OAM gateway is {{ external_oam_gateway_address }}
      - OAM floating ip is {{ external_oam_floating_address }}
      - Management dynamic address allocation is {{ management_dynamic_address_allocation }}
      - Cluster host dynamic address allocation is {{ cluster_host_dynamic_address_allocation }}
      - Docker registries is {{ docker_registries }}
      - Docker HTTP proxy is {{ docker_http_proxy }}
      - Docker HTTPS proxy is {{ docker_https_proxy }}
      - Docker no proxy list is {{ docker_no_proxy }}
      - Applications are {{ applications }}

- debug:
    msg:
      - Admin subnet is {{ admin_subnet }}
  when: admin_network is defined

# System parameters config validation
- block:
  - name: Set system mode fact
    set_fact:
      system_mode: "{{ system_mode|lower }}"

  - block:
    - debug:
        msg: "System type is Standard, system mode will be set to duplex."
    - name: Set system mode to duplex for Standard system
      set_fact:
        system_mode: duplex
    when: system_type == 'Standard'

  - name: Validate system mode if system type is All-in-one
    fail:
      msg: "Invalid system mode. Valid values are: simplex, duplex or duplex-direct."
    when: >
      (system_mode != 'simplex' and
       system_mode != 'duplex' and
       system_mode != 'duplex-direct') and
      (system_type == 'All-in-one')

  - name: Validate virtual system setting
    fail:
      msg: "virtual_system is misconfigured. Valid value is either 'True' or 'False'."
    when: >
      (virtual_system is defined and
       not virtual_system | type_debug == 'bool')

  - name: Fail if virtual system type is not All-in-one
    fail:
      msg: "Virtual system setting is only supported for All-in-one system"
    when: >
      (virtual_system is defined and
       virtual_system|bool and
       system_type != 'All-in-one')

  - name: Validate distributed cloud role
    fail:
      msg: "Invalid distributed cloud role. Valid values are: none, systemcontroller, or subcloud."
    when: >
      (distributed_cloud_role != 'none' and
       distributed_cloud_role != 'systemcontroller' and
       distributed_cloud_role != 'subcloud')

  - block:
    - name: Validate system type and system mode if distributed cloud role is system controller
      fail:
        msg: "A simplex All-in-one controller cannot be configured as Distributed Cloud System Controller"
      when: system_mode == 'simplex'

    - name: Validate virtual system setting if distributed cloud role is system controller
      fail:
        msg: "Virtual system setting is not supported for Distributed Cloud System Controller"
      when: >
        (virtual_system is defined and
         virtual_system|bool)

    when: >
      (distributed_cloud_role == 'systemcontroller' and
       system_type == 'All-in-one')

  - name: Checking registered timezones
    stat:
      path: "{{ '/usr/share/zoneinfo/' + timezone }}"
    register: timezone_file

  - name: Fail if provided timezone is unknown
    fail: msg="The provided timezone {{ timezone }} is invalid."
    when: not timezone_file.stat.exists

  - name: Fail if the number of dns servers provided is not at least 1 and no more than 3
    fail:
      msg: "The number of DNS servers exceeds maximum allowable number of 3."
    when: (dns_servers | length == 0) or (dns_servers | length > 3)


# DNS servers config validation
- name: Check format of DNS server IP(s)
  debug:
    msg: "DNS Server: {{ item }}"
  failed_when: item | ipaddr == False
  with_items: "{{ dns_servers }}"

- name: Update resolv.conf with list of dns servers
  lineinfile:
    path: /etc/resolv.conf
    line: "nameserver {{ item }}"
  with_items: "{{ dns_servers }}"

# Networks config validation
- block:
  - name: Validate provided subnets (both IPv4 & IPv6 notations)
    debug:
      msg: "{{ item.key }}: {{ item.value }}"
    failed_when: item.value|ipaddr == False
    with_dict: "{{ network_params }}"

  - set_fact:
      ipv4_addressing: "{{ network_params.management_subnet|ipv4 }}"
      ipv6_addressing: "{{ network_params.management_subnet|ipv6 }}"

  - name: Validate all network subnets are IPv4
    debug:
      msg: "All infrastructure and cluster subnets must be the same IP version"
    failed_when: item|ipv4 == False
    with_items:
      - "{{ network_params.management_subnet }}"
      - "{{ network_params.cluster_host_subnet }}"
      - "{{ network_params.cluster_pod_subnet }}"
      - "{{ network_params.cluster_service_subnet }}"
      - "{{ network_params.external_oam_subnet }}"
      - "{{ network_params.management_multicast_subnet }}"
      - "{{ network_params.admin_subnet | default([]) }}"
    when: ipv4_addressing != False

  - name: Validate all network subnets are IPv6
    debug:
      msg: "All infrastructure and cluster subnets must be the same IP version"
    failed_when: item|ipv6 == False
    with_items:
      - "{{ network_params.management_subnet }}"
      - "{{ network_params.cluster_host_subnet }}"
      - "{{ network_params.cluster_pod_subnet }}"
      - "{{ network_params.cluster_service_subnet }}"
      - "{{ network_params.external_oam_subnet }}"
      - "{{ network_params.management_multicast_subnet }}"
      - "{{ network_params.admin_subnet | default([]) }}"
    when: ipv6_addressing != False

  - name: Validate pxeboot subnet is IPv4
    debug:
      msg: "pxeboot_subnet subnet must always be IPv4"
    failed_when: network_params.pxeboot_subnet|ipv4 == False

  - name: Generate warning if subnet prefix is not typical for Standard systems
    debug:
      msg: "WARNING: Subnet prefix of less than /24 is not typical. This will affect scaling of the system!"
    when: item|ipaddr('prefix')|int < typical_subnet_prefix and system_type == 'Standard'
    with_items:
      - "{{ network_params.pxeboot_subnet }}"
      - "{{ network_params.management_subnet }}"
      - "{{ network_params.cluster_host_subnet }}"
      - "{{ network_params.external_oam_subnet }}"
      - "{{ network_params.management_multicast_subnet }}"

  - block:
    - name: Fail if IPv6 prefix length is too short
      fail:
        msg: "IPv6 minimum prefix length is {{ minimum_prefix_length }}"
      when: network_params.management_subnet|ipaddr('prefix')|int < minimum_ipv6_prefix_length

    when: ipv6_addressing != False

  - name: Fail if management address allocation is misconfigured
    fail:
      msg: "management_dynamic_address_allocation is misconfigured. Valid value is either 'True' or 'False'."
    when: not management_dynamic_address_allocation | type_debug == 'bool'

  - name: Fail if cluster-host address allocation is misconfigured
    fail:
      msg: "cluster_host_dynamic_address_allocation is misconfigured. Valid value is either 'True' or 'False'."
    when: not cluster_host_dynamic_address_allocation | type_debug == 'bool'

  - name: Fail if management start or end address is not configured for System Controller
    fail:
      msg: >-
           management_start_address and management_end_address are required
           for System Controller as this configuration requires address space
           left for gateway address(es).
    when: >
      (distributed_cloud_role == 'systemcontroller' and
      (management_start_address == 'derived' or management_end_address == 'derived'))

  # The provided subnets have passed validation, set the default addresses
  # based on the subnet values
  - name: Set default start and end addresses based on provided subnets
    set_fact:
      default_pxeboot_start_address: "{{ (pxeboot_subnet | ipaddr(1)).split('/')[0] }}"
      default_pxeboot_end_address: "{{ (pxeboot_subnet | ipaddr(-2)).split('/')[0] }}"
      default_management_start_address: "{{ (management_subnet | ipaddr(1)).split('/')[0] }}"
      default_management_end_address: "{{ (management_subnet | ipaddr(-2)).split('/')[0] }}"
      default_cluster_host_start_address: "{{ (cluster_host_subnet | ipaddr(1)).split('/')[0] }}"
      default_cluster_host_end_address: "{{ (cluster_host_subnet | ipaddr(-2)).split('/')[0] }}"
      default_cluster_pod_start_address: "{{ (cluster_pod_subnet | ipaddr(1)).split('/')[0] }}"
      default_cluster_pod_end_address: "{{ (cluster_pod_subnet | ipaddr(-2)).split('/')[0] }}"
      default_cluster_service_start_address: "{{ (cluster_service_subnet | ipaddr(1)).split('/')[0] }}"
      default_cluster_service_end_address: "{{ (cluster_service_subnet | ipaddr(-2)).split('/')[0] }}"
      default_external_oam_start_address: "{{ (external_oam_subnet | ipaddr(1)).split('/')[0] }}"
      default_external_oam_end_address: "{{ (external_oam_subnet | ipaddr(-2)).split('/')[0] }}"
      default_management_multicast_start_address: "{{ (management_multicast_subnet | ipaddr(1)).split('/')[0] }}"
      default_management_multicast_end_address: "{{ (management_multicast_subnet | ipaddr(-2)).split('/')[0] }}"
      default_external_oam_node_0_address: "{{ external_oam_floating_address | ipmath(1) }}"
      default_external_oam_node_1_address: "{{ external_oam_floating_address | ipmath(2) }}"

  - name: Set default start and end admin network addresses based on provided subnets
    set_fact:
      default_admin_start_address: "{{ (admin_subnet | ipaddr(1)).split('/')[0] }}"
      default_admin_end_address: "{{ (admin_subnet | ipaddr(-2)).split('/')[0] }}"
    when: admin_network is defined

  - name: Build address pairs for validation, merging default and user provided values
    set_fact:
      address_pairs:
        pxeboot:
          start:
            "{{ pxeboot_start_address if pxeboot_start_address != 'derived'
            else default_pxeboot_start_address }}"
          end:
            "{{ pxeboot_end_address if pxeboot_end_address != 'derived'
            else default_pxeboot_end_address }}"
          subnet: "{{ network_params.pxeboot_subnet }}"
        management:
          start:
            "{{ management_start_address if management_start_address != 'derived'
            else default_management_start_address }}"
          end:
            "{{ management_end_address if management_end_address != 'derived'
            else default_management_end_address }}"
          subnet: "{{ network_params.management_subnet }}"
        cluster_host:
          start:
            "{{ cluster_host_start_address if cluster_host_start_address != 'derived'
            else default_cluster_host_start_address }}"
          end:
            "{{ cluster_host_end_address if cluster_host_end_address != 'derived'
            else default_cluster_host_end_address}}"
          subnet: "{{ network_params.cluster_host_subnet }}"
        cluster_pod:
          start:
            "{{ cluster_pod_start_address if cluster_pod_start_address != 'derived'
            else default_cluster_pod_start_address }}"
          end:
            "{{ cluster_pod_end_address if cluster_pod_end_address != 'derived'
            else default_cluster_pod_end_address }}"
          subnet: "{{ network_params.cluster_pod_subnet }}"
        cluster_service:
          start:
            "{{ cluster_service_start_address if cluster_service_start_address != 'derived'
            else default_cluster_service_start_address }}"
          end:
            "{{ cluster_service_end_address if cluster_service_end_address != 'derived'
            else default_cluster_service_end_address }}"
          subnet: "{{ network_params.cluster_service_subnet }}"
        oam:
          start:
            "{{ external_oam_start_address if external_oam_start_address != 'derived'
            else default_external_oam_start_address }}"
          end:
            "{{ external_oam_end_address if external_oam_end_address != 'derived'
            else default_external_oam_end_address }}"
          subnet: "{{ network_params.external_oam_subnet }}"
        multicast:
          start:
            "{{ management_multicast_start_address if management_multicast_start_address != 'derived'
            else default_management_multicast_start_address }}"
          end:
            "{{ management_multicast_end_address if management_multicast_end_address != 'derived'
            else default_management_multicast_end_address }}"
          subnet: "{{ network_params.management_multicast_subnet }}"
        oam_node:
          start:
            "{{ external_oam_node_0_address if external_oam_node_0_address != 'derived'
            else default_external_oam_node_0_address }}"
          end:
            "{{ external_oam_node_1_address if external_oam_node_1_address != 'derived'
            else default_external_oam_node_1_address }}"
          subnet: "{{ network_params.external_oam_subnet }}"

  - name: Build admin address pairs for validation, merging default and user provided values
    set_fact:
      admin_pairs:
        start:
          "{{ admin_start_address if admin_start_address != 'derived'
          else default_admin_start_address }}"
        end:
          "{{ admin_end_address if admin_end_address != 'derived'
          else default_admin_end_address }}"
        subnet: "{{ network_params.admin_subnet }}"
    when: admin_network is defined

  - name: Add admin address pairs to address pairs
    set_fact:
      address_pairs: "{{ address_pairs | combine({'admin': admin_pairs}) }}"
    when: admin_network is defined

  - include: validate_address_range.yml
    with_dict: "{{ address_pairs }}"

  - name: Set OAM address list
    set_fact:
      OAM_addresses: "{{ [external_oam_floating_address] }}"

  - name: Update OAM address list for duplex
    set_fact:
      OAM_addresses: "{{ OAM_addresses + [ address_pairs['oam_node']['start'], address_pairs['oam_node']['end'] ] }}"
    when: system_mode != 'simplex'

  - name: Set floating addresses based on subnets or start addresses
    set_fact:
      # Not sure why ipaddr('address') and ipsubnet filter did not extract
      # the IP from CIDR input. Resort to string split for now.
      controller_floating_address: "{{ address_pairs['management']['start'] }}"
      controller_pxeboot_floating_address: "{{ address_pairs['pxeboot']['start'] }}"
      cluster_floating_address: "{{ address_pairs['cluster_host']['start'] }}"

  - name: Set subcloud admin floating address
    set_fact:
      controller_admin_floating_address: "{{ address_pairs['admin']['start'] }}"
    when: address_pairs.admin is defined

  - name: Set subcloud floating address
    set_fact:
      sc_floating_address: "{{ controller_admin_floating_address
                           if controller_admin_floating_address is defined
                           else address_pairs.management.start }}"
    when: distributed_cloud_role == 'subcloud'

  - name: Set derived facts for subsequent tasks/roles
    set_fact:
      derived_network_params:
        'management_interface': lo
        'management_interface_name': lo
        'controller_0_address': "{{ controller_floating_address|ipmath(1) }}"
        'controller_1_address': "{{ controller_floating_address|ipmath(2) }}"
        'controller_pxeboot_address_0': "{{ controller_pxeboot_floating_address|ipmath(1) }}"
        'controller_pxeboot_address_1': "{{ controller_pxeboot_floating_address|ipmath(2) }}"

      # Make common facts available to other roles
      config_workdir: "{{ config_workdir }}"
      dns_servers: "{{ dns_servers }}"

      # Derived network parameters that don't apply to bootstrap_config but are required for
      # subsequent roles
      management_subnet_prefix: "{{ management_subnet | ipaddr('prefix') }}"
      management_broadcast: "{{ management_subnet | ipaddr('broadcast') }}"
      pxe_subnet_prefix: "{{ pxeboot_subnet | ipaddr('prefix') }}"
      cluster_subnet_prefix: "{{ cluster_host_subnet | ipaddr('prefix') }}"
      cluster_broadcast: "{{ cluster_host_subnet | ipaddr('broadcast') }}"
      controller_0_cluster_host: "{{ cluster_floating_address|ipmath(1) }}"
      controller_1_cluster_host: "{{ cluster_floating_address|ipmath(2) }}"
      controller_floating_address_url:
        "{{ controller_floating_address|ipwrap if controller_floating_address|ipv6 != False
        else controller_floating_address}}"

  - name: Set facts for IP address provisioning against loopback interface
    set_fact:
      mgmt_virtual: "{{ derived_network_params.controller_0_address }}/{{ management_subnet_prefix }}"
      cluster_virtual: "{{ controller_0_cluster_host }}/{{ cluster_subnet_prefix }}"
      pxe_virtual: "{{ controller_pxeboot_floating_address }}/{{ pxe_subnet_prefix }}"
      cluster_floating_virtual: "{{ cluster_floating_address }}/{{ cluster_subnet_prefix }}"
      mgmt_floating_virtual: "{{ controller_floating_address }}/{{ management_subnet_prefix }}"

  - name: Set facts for admin IP address provisioning against loopback interface
    set_fact:
      admin_broadcast: "{{ admin_subnet | ipaddr('broadcast') }}"
      admin_virtual: "{{ controller_admin_floating_address }}/{{ admin_subnet | ipaddr('prefix') }}"
    when: admin_network is defined

# Docker config validation
- block:
  - set_fact:
      use_default_registries: true
      k8s_registry: "{{ default_k8s_registry }}"
      gcr_registry: "{{ default_gcr_registry }}"
      quay_registry: "{{ default_quay_registry }}"
      docker_registry: "{{ default_docker_registry }}"
      elastic_registry: "{{ default_elastic_registry }}"
      ghcr_registry: "{{ default_ghcr_registry }}"
      registryk8s_registry: "{{ default_registryk8s_registry }}"
      icr_registry: "{{ default_icr_registry }}"
      default_no_proxy:
        - localhost
        - 127.0.0.1
        - registry.local
        - "{{ cluster_service_start_address if cluster_service_start_address != 'derived'
            else default_cluster_service_start_address }}"
        - "{{ controller_floating_address }}"
        - "{{ derived_network_params.controller_0_address }}"
        - "{{ external_oam_floating_address }}"
        - "{{ address_pairs['oam_node']['start'] }}"
      non_sx_proxy_addons:
        - "{{ derived_network_params.controller_1_address }}"
        - "{{ address_pairs['oam_node']['end'] }}"
      docker_no_proxy_combined: []

  - block:
    - name: Set subcloud no proxy list
      set_fact:
        subcloud_no_proxy:
          - registry.central
          - "{{ system_controller_oam_floating_address }}"
    - name: Update default no proxy list for subcloud
      set_fact:
        default_no_proxy: "{{ default_no_proxy + subcloud_no_proxy }}"
    when: distributed_cloud_role == 'subcloud'

  - block:
    - name: Set default no-proxy address list (non simplex)
      set_fact:
        default_no_proxy: "{{ default_no_proxy + non_sx_proxy_addons }}"
      when: system_mode != 'simplex'

    - block:
      - name: Validate http proxy urls
        include: validate_url.yml input_url={{ item }}
        with_items:
          - "{{ docker_http_proxy }}"
          - "{{ docker_https_proxy }}"

    - block:
      - name: Validate no proxy addresses
        include: validate_address.yml input_address={{ item }}
        with_items: "{{ docker_no_proxy }}"
        when: docker_no_proxy|length > 0

    - name: Add user defined no-proxy address list to default
      set_fact:
        docker_no_proxy_combined: "{{ default_no_proxy | union(docker_no_proxy) | ipwrap | unique }}"

    when: use_docker_proxy

  - block:
    - name: Turn on use_defaults_registry flag
      set_fact:
        use_defaults_registry: true
        k8s_registry: "{{ k8s_registry | combine(docker_registries_with_secrets['defaults'], recursive=true) }}"
        gcr_registry: "{{ gcr_registry | combine(docker_registries_with_secrets['defaults'], recursive=true) }}"
        quay_registry: "{{ quay_registry | combine(docker_registries_with_secrets['defaults'], recursive=true) }}"
        docker_registry: "{{ docker_registry | combine(docker_registries_with_secrets['defaults'], recursive=true) }}"
        elastic_registry: "{{ elastic_registry | combine(docker_registries_with_secrets['defaults'], recursive=true) }}"
        ghcr_registry: "{{ ghcr_registry | combine(docker_registries_with_secrets['defaults'], recursive=true) }}"
        registryk8s_registry: "{{ registryk8s_registry | combine(docker_registries_with_secrets['defaults'],
                              recursive=true) }}"
        icr_registry: "{{ icr_registry | combine(docker_registries_with_secrets['defaults'], recursive=true) }}"

    when: docker_registries['defaults'] is defined and docker_registries['defaults'] is not none

  - set_fact:
      k8s_registry:
        "{{ k8s_registry | combine(docker_registries_with_secrets[default_k8s_registry.url], recursive=true) }}"
    when: (docker_registries[default_k8s_registry.url]['url'] is not defined or
           (docker_registries[default_k8s_registry.url]['url'] is not none and
           docker_registries[default_k8s_registry.url]['url'] != default_k8s_registry.url))

  - set_fact:
      gcr_registry:
        "{{ gcr_registry | combine(docker_registries_with_secrets[default_gcr_registry.url], recursive=true) }}"
    when: (docker_registries[default_gcr_registry.url]['url'] is not defined or
           (docker_registries[default_gcr_registry.url]['url'] is not none and
           docker_registries[default_gcr_registry.url]['url'] != default_gcr_registry.url))

  - set_fact:
      quay_registry:
        "{{ quay_registry | combine(docker_registries_with_secrets[default_quay_registry.url], recursive=true) }}"
    when: (docker_registries[default_quay_registry.url]['url'] is not defined or
           (docker_registries[default_quay_registry.url]['url'] is not none and
           docker_registries[default_quay_registry.url]['url'] != default_quay_registry.url))

  - set_fact:
      docker_registry:
        "{{ docker_registry | combine(docker_registries_with_secrets[default_docker_registry.url], recursive=true) }}"
    when: (docker_registries[default_docker_registry.url]['url'] is not defined or
           (docker_registries[default_docker_registry.url]['url'] is not none and
           docker_registries[default_docker_registry.url]['url'] != default_docker_registry.url))

  - set_fact:
      elastic_registry:
        "{{ elastic_registry | combine(docker_registries_with_secrets[default_elastic_registry.url], recursive=true) }}"
    when: (docker_registries[default_elastic_registry.url]['url'] is not defined or
           (docker_registries[default_elastic_registry.url]['url'] is not none and
           docker_registries[default_elastic_registry.url]['url'] != default_elastic_registry.url))

  - set_fact:
      ghcr_registry:
        "{{ ghcr_registry | combine(docker_registries_with_secrets[default_ghcr_registry.url], recursive=true) }}"
    when: (docker_registries[default_ghcr_registry.url]['url'] is not defined or
           (docker_registries[default_ghcr_registry.url]['url'] is not none and
           docker_registries[default_ghcr_registry.url]['url'] != default_ghcr_registry.url))

  - set_fact:
      registryk8s_registry:
        "{{ registryk8s_registry | combine(docker_registries_with_secrets[default_registryk8s_registry.url],
        recursive=true) }}"
    when: (docker_registries[default_registryk8s_registry.url]['url'] is not defined or
           (docker_registries[default_registryk8s_registry.url]['url'] is not none and
           docker_registries[default_registryk8s_registry.url]['url'] != default_registryk8s_registry.url))

  - set_fact:
      icr_registry:
        "{{ icr_registry | combine(docker_registries_with_secrets[default_icr_registry.url], recursive=true) }}"
    when: (docker_registries[default_icr_registry.url]['url'] is not defined or
           (docker_registries[default_icr_registry.url]['url'] is not none and
           docker_registries[default_icr_registry.url]['url'] != default_icr_registry.url))

  - name: Update use_default_registries flag
    set_fact:
      use_default_registries: false
    when: use_defaults_registry or
          docker_registries|length != 5 or
          k8s_registry != default_k8s_registry or
          gcr_registry != default_gcr_registry or
          quay_registry != default_quay_registry or
          docker_registry != default_docker_registry or
          elastic_registry != default_elastic_registry or
          ghcr_registry != default_ghcr_registry or
          registryk8s_registry != default_registryk8s_registry or
          icr_registry != default_icr_registry

  - block:
    - name: Validate registry type if specified
      fail:
        msg: "Registry type for {{ item.key }} is not supported. Valid value is either 'docker' or 'aws-ecr'."
      with_dict: "{{ docker_registries }}"
      when: (item.value.type is defined and
            item.value.type not in ['docker', 'aws-ecr'])

    - name: Fail if secure registry flag is misconfigured
      fail:
        msg: "'secure' parameter of registry {{ item.key }} is misconfigured. Valid value is either 'True' or 'False'."
      with_dict: "{{ docker_registries }}"
      when: (item.value.secure is defined and
            not (item.value.secure|type_debug == 'bool'))

    - include: validate_address.yml input_address={{ item }}
      with_items:
        - "{{ k8s_registry.url }}"
        - "{{ gcr_registry.url }}"
        - "{{ quay_registry.url }}"
        - "{{ docker_registry.url }}"
        - "{{ elastic_registry.url }}"
        - "{{ ghcr_registry.url }}"
        - "{{ registryk8s_registry.url }}"
        - "{{ icr_registry.url }}"
    when: not use_default_registries

- name: Validate additional_local_registry_images list
  fail:
    msg: "additional_local_registry_images must be a list"
  when: additional_local_registry_images | type_debug != 'list'

# Docker images archive source validation
- block:
  - set_fact:
      images_archive_md5_file: "{{ images_archive_dir }}/container-image.tar.gz.md5"

  - name: Check if images archive(s) exists
    find:
      paths: "{{ images_archive_dir }}"
      patterns: "*.tar,*.tar.gz"
      recurse: no
    register: images_archive_find_output

  - debug: var=images_archive_find_output.files
  - set_fact:
      num_of_archive_files_on_disk: "{{ images_archive_find_output.files|length }}"

  - block:
    - name: Check if images archive md5 exists
      stat:
        path: "{{ images_archive_md5_file }}"
      register: images_archive_md5

    - block:
      - name: Get number of archive files in md5 file
        shell: cat {{ images_archive_md5_file }} | wc -l
        register: file_count

      - name: Print warning if md5 file content is invalid
        debug:
          msg: >-
               WARNING: Number of archive files listed in {{ images_archive_md5_file }}
               does not match with the number of image archive files on disk. Fall
               back to downloading images...
        when: file_count.stdout != num_of_archive_files_on_disk

      - block:
        - name: Verify container images archive file checksum
          command: md5sum -c {{ images_archive_md5_file }}
          args:
            chdir: "{{ images_archive_dir }}"
          register: checksum_result
          failed_when: false

        - debug: var=checksum_result

        - name: Print warning if images archive checksum failed
          debug:
            msg: >-
                 WARNING: Images archive checksum failed. Fall back to downloading
                 images...
          when: checksum_result.rc != 0

        - name: Turn on images archive flag if file checksum is successfully validated
          set_fact:
            images_archive_exists: true
            images_archive_files: "{{ images_archive_find_output.files }}"
          when: checksum_result.rc == 0
        when: file_count.stdout == num_of_archive_files_on_disk

      when: images_archive_md5.stat.exists

    when: num_of_archive_files_on_disk|int > 0

# System applications validation
- name: Validate applications
  include: validate_application.yml application={{ item }}
  with_items: "{{ applications }}"
  when: applications

- name: Build application list
  set_fact:
    all_applications: []

- name: Append applications to application list
  set_fact:
    all_applications: "{{ all_applications }} + [ '{{ item.keys()|list|first }}' ]"
  with_items: "{{ applications }}"

- name: Get the name of the nginx tarball
  find:
    paths: "/usr/local/share/applications/helm/"
    patterns: 'nginx-ingress-controller-[^-]*-[^-]*\.tgz'
    use_regex: yes
  register: find_nginx_tarball_output

- name: Get the name of the cert manager tarball
  find:
    paths: "/usr/local/share/applications/helm/"
    patterns: 'cert-manager-[^-]*-[^-]*\.tgz'
    use_regex: yes
  register: find_cert_manager_tarball_output

# we prepend nginx and append cert manager to try and enforce ordering
# nginx need to be applied before cert manager
- name: Append default nginx entry if not present
  set_fact:
    applications: "[ {'{{ item.path }}': None}] + {{ applications }}"
  with_items: "{{ find_nginx_tarball_output.files }}"
  when: item.path not in all_applications

- name: Append default cert manager entry if not present
  set_fact:
    applications: "{{ applications }} + [ {'{{ item.path }}': None}]"
  with_items: "{{ find_cert_manager_tarball_output.files }}"
  when: item.path not in all_applications

- block:
  - name: Retrieve list of applications from sysinv
    shell: "source /etc/platform/openrc; system application-list --nowrap | awk '{print $2}'"
    register: application_list_output
    failed_when: false

  - name: Build list of existing applications
    set_fact:
      old_application_list: "{{ application_list_output.stdout.splitlines() }}"

  # TODO: modify system application-list so this is no longer needed
  # refer to system host-list's column and format options
  # the output of system application-list has 3 lines of header
  # ------
  # application
  # -----
  # get rid of that in our output that we captured
  - name: Remove header from application list output
    set_fact:
      old_application_list: "{{ old_application_list[3:] }}"

  # we need to purge old applications here because the replay might involve a teardown
  # of the kubernetes cluster. This would result in sysinv being unable to clean up
  # the deployed applications on its side
  - block:
    - name: Purge old applications
      include: purge_application.yml application={{ item }}
      with_items: "{{ old_application_list }}"

    # we check the return code from sysinv to see that application-list ran successfully
    # in a non replay, or weird replay cases, sysinv could be not up at which point
    # there is no point in trying to purge applications
    when: application_list_output.rc == 0 and old_application_list | length > 0
  when: replayed

- name: Validate apiserver_cert_sans list
  fail:
    msg: "apiserver_cert_sans must be a list"
  when: apiserver_cert_sans | type_debug != 'list'

- name: Validate apiserver_cert_sans entries
  include: validate_address.yml input_address={{ item }}
  with_items: "{{ apiserver_cert_sans }}"

- name: Verify that either both etcd root ca cert and key are defined or not at all
  fail:
    msg: "etcd_root_ca_cert and etcd_root_ca_key must be provided as a pair"
  when: (etcd_root_ca_cert and not etcd_root_ca_key) or
        (not etcd_root_ca_cert and etcd_root_ca_key)

- name: Check for etcd_root_ca_cert file
  fail:
    msg: "etcd_root_ca_cert file not found. ({{ etcd_root_ca_cert }})"
  when: etcd_root_ca_cert and (not etcd_root_ca_cert is file)

- name: Check for etcd_root_ca_key file
  fail:
    msg: "etcd_root_ca_key file not found. ({{ etcd_root_ca_key }})"
  when: etcd_root_ca_key and (not etcd_root_ca_key is file)

- name: Verify that either both Kubernetes root ca cert and key are defined or not at all
  fail:
    msg: "k8s_root_ca_cert and k8s_root_ca_key must be provided as a pair"
  when: (k8s_root_ca_cert and not k8s_root_ca_key) or
        (not k8s_root_ca_cert and k8s_root_ca_key)

- name: Check for k8s_root_ca_cert file
  fail:
    msg: "k8s_root_ca_cert file not found. ({{ k8s_root_ca_cert }})"
  when: k8s_root_ca_cert and (not k8s_root_ca_cert is file)

- name: Check for k8s_root_ca_key file
  fail:
    msg: "k8s_root_ca_key file not found. ({{ k8s_root_ca_key }})"
  when: k8s_root_ca_key and (not k8s_root_ca_key is file)

- name: Check for ssl_ca_cert file
  fail:
    msg: "ssl_ca_cert file not found. ({{ ssl_ca_cert }})"
  when: mode != 'restore' and ssl_ca_cert is defined and (not ssl_ca_cert is file)

- name: Check OpenID Connect parameters
  fail:
    msg: "If OpenID Connect parameters are specified, you must specify all 3
          apiserver_oidc: client_id, issuer_url, username_claim or
          apiserver_oidc: groups_claim in addition to the previous 3."
  when: not ((apiserver_oidc|length == 0)
        or
        ((apiserver_oidc|length == 3) and
        apiserver_oidc.client_id is defined and
        apiserver_oidc.issuer_url is defined and
        apiserver_oidc.username_claim is defined)
        or
        ((apiserver_oidc|length == 4) and
        apiserver_oidc.client_id is defined and
        apiserver_oidc.issuer_url is defined and
        apiserver_oidc.username_claim is defined and
        apiserver_oidc.groups_claim is defined))

- name: Check overridden kubernetes_version matches the backup.
  fail:
    msg: >
      Cannot override kubernetes_version {{ kubernetes_version }}
      different than value {{ restore_k8s_version }} in backup tarball!
  when: (kubernetes_version is defined) and
        (restore_k8s_version is defined) and
        (kubernetes_version != restore_k8s_version)

- name: Check extraVolumes configuration.
  fail:
    msg: >
      Attribute is missing in extra volume {{ item.name }}.
      Or readOnly attribute's value is not 'false' or 'true'
      Or pathType attribute's value is not 'File' or 'DirectoryOrCreate'
  when: (item.name is not defined) or
        (item.mountPath is not defined) or
        (item.hostPath is not defined) or
        (item.pathType is not defined) or
        (item.pathType != 'File' and item.pathType != 'DirectoryOrCreate') or
        (item.readOnly is not defined) or
        (item.readOnly | type_debug != 'bool')
  loop: "{{ apiserver_extra_volumes + controllermanager_extra_volumes + scheduler_extra_volumes }}"

# Wipe ceph osds
# Note that due to Ansible mishandling of boolean values via extra-vars we are
# adding supplementary validation here.
# See: https://github.com/ansible/ansible/issues/17193
- name: Check for Ceph data wipe flag
  fail:
    msg: "wipe_ceph_osds is misconfigured. Valid value is either 'true' or 'false'"
  when: (mode == "restore") and (not wipe_ceph_osds | type_debug == 'bool') and
        (wipe_ceph_osds != 'true') and
        (wipe_ceph_osds != 'false')

- block:
  - name: Wipe ceph osds
    script: wipe_osds.sh
    register: results

  - name: Result of wiping ceph osds
    debug: var=results.stdout_lines

  when: (mode == "bootstrap") or
        (mode == "restore" and wipe_ceph_osds|bool)

# bootstrap_config ini file generation
- block:
  - name: Create config workdir
    file:
      path: "{{ config_workdir }}"
      state: directory
      owner: root
      group: root
      mode: 0755

  - name: Generate config ini file for python sysinv db population script
    lineinfile:
      path: "{{ bootstrap_config_file }}"
      line: "{{ item }}"
      create: yes
    with_items:
      - "[BOOTSTRAP_CONFIG]"
      - "CONTROLLER_HOSTNAME=controller-0"
      - "SYSTEM_TYPE={{ system_type }}"
      - "SYSTEM_MODE={{ system_mode }}"
      - "VIRTUAL_SYSTEM={{ virtual_system | default(False) }}"
      - "TIMEZONE={{ timezone }}"
      - "DISTRIBUTED_CLOUD_ROLE={{ distributed_cloud_role }}"
      - "REGION_NAME={{ region_name }}"
      - "SW_VERSION={{ software_version }}"
      - "NAMESERVERS={{ dns_servers| join(',') }}"
      - "PXEBOOT_SUBNET={{ pxeboot_subnet }}"
      - "PXEBOOT_START_ADDRESS={{ address_pairs['pxeboot']['start'] }}"
      - "PXEBOOT_END_ADDRESS={{ address_pairs['pxeboot']['end'] }}"
      - "MANAGEMENT_SUBNET={{ management_subnet }}"
      - "MANAGEMENT_START_ADDRESS={{ address_pairs['management']['start'] }}"
      - "MANAGEMENT_END_ADDRESS={{ address_pairs['management']['end'] }}"
      - "MANAGEMENT_GATEWAY_ADDRESS={{ management_gateway_address | default('undef')}}"
      - "MANAGEMENT_DYNAMIC_ADDRESS_ALLOCATION={{ management_dynamic_address_allocation }}"
      - "MANAGEMENT_INTERFACE=lo"
      - "CONTROLLER_0_ADDRESS={{ derived_network_params.controller_0_address }}"
      - "CLUSTER_HOST_SUBNET={{ cluster_host_subnet }}"
      - "CLUSTER_HOST_START_ADDRESS={{ address_pairs['cluster_host']['start'] }}"
      - "CLUSTER_HOST_END_ADDRESS={{ address_pairs['cluster_host']['end'] }}"
      - "CLUSTER_HOST_DYNAMIC_ADDRESS_ALLOCATION={{ cluster_host_dynamic_address_allocation }}"
      - "CLUSTER_POD_SUBNET={{ cluster_pod_subnet }}"
      - "CLUSTER_POD_START_ADDRESS={{ address_pairs['cluster_pod']['start'] }}"
      - "CLUSTER_POD_END_ADDRESS={{ address_pairs['cluster_pod']['end'] }}"
      - "CLUSTER_SERVICE_SUBNET={{ cluster_service_subnet }}"
      - "CLUSTER_SERVICE_START_ADDRESS={{ address_pairs['cluster_service']['start'] }}"
      - "CLUSTER_SERVICE_END_ADDRESS={{ address_pairs['cluster_service']['end'] }}"
      - "EXTERNAL_OAM_SUBNET={{ external_oam_subnet }}"
      - "EXTERNAL_OAM_START_ADDRESS={{ address_pairs['oam']['start'] }}"
      - "EXTERNAL_OAM_END_ADDRESS={{ address_pairs['oam']['end'] }}"
      - "EXTERNAL_OAM_GATEWAY_ADDRESS={{ external_oam_gateway_address }}"
      - "EXTERNAL_OAM_FLOATING_ADDRESS={{ external_oam_floating_address }}"
      - "EXTERNAL_OAM_0_ADDRESS={{ address_pairs['oam_node']['start'] }}"
      - "EXTERNAL_OAM_1_ADDRESS={{ address_pairs['oam_node']['end'] }}"
      - "MANAGEMENT_MULTICAST_SUBNET={{ management_multicast_subnet }}"
      - "MANAGEMENT_MULTICAST_START_ADDRESS={{ address_pairs['multicast']['start'] }}"
      - "MANAGEMENT_MULTICAST_END_ADDRESS={{ address_pairs['multicast']['end'] }}"
      - "SYSTEM_CONTROLLER_SUBNET={{ system_controller_subnet }}"
      - "SYSTEM_CONTROLLER_FLOATING_ADDRESS={{ system_controller_floating_address }}"
      - "SYSTEM_CONTROLLER_OAM_SUBNET={{ system_controller_oam_subnet }}"
      - "SYSTEM_CONTROLLER_OAM_FLOATING_ADDRESS={{ system_controller_oam_floating_address }}"
      - "ADMIN_SUBNET={{ admin_subnet | default('undef') }}"
      - "ADMIN_START_ADDRESS={{ address_pairs['admin']['start'] | default('undef') }}"
      - "ADMIN_END_ADDRESS={{ address_pairs['admin']['end'] | default('undef') }}"
      - "ADMIN_GATEWAY_ADDRESS={{ admin_gateway_address | default('undef') }}"
      - "ADMIN_INTERFACE={{ 'lo' if admin_network is defined else 'undef' }}"
      - "DOCKER_HTTP_PROXY={{ docker_http_proxy }}"
      - "DOCKER_HTTPS_PROXY={{ docker_https_proxy }}"
      - "DOCKER_NO_PROXY={{ docker_no_proxy_combined | join(',') }}"
      - "K8S_REGISTRY={{ k8s_registry.url }}"
      - "GCR_REGISTRY={{ gcr_registry.url }}"
      - "QUAY_REGISTRY={{ quay_registry.url }}"
      - "DOCKER_REGISTRY={{ docker_registry.url }}"
      - "ELASTIC_REGISTRY={{ elastic_registry.url }}"
      - "GHCR_REGISTRY={{ ghcr_registry.url }}"
      - "REGISTRYK8S_REGISTRY={{ registryk8s_registry.url }}"
      - "ICR_REGISTRY={{ icr_registry.url }}"
      - "K8S_REGISTRY_TYPE={{ k8s_registry.type | default('docker') }}"
      - "GCR_REGISTRY_TYPE={{ gcr_registry.type | default('docker') }}"
      - "QUAY_REGISTRY_TYPE={{ quay_registry.type | default('docker') }}"
      - "DOCKER_REGISTRY_TYPE={{ docker_registry.type | default('docker') }}"
      - "ELASTIC_REGISTRY_TYPE={{ elastic_registry.type | default('docker') }}"
      - "GHCR_REGISTRY_TYPE={{ ghcr_registry.type | default('docker') }}"
      - "REGISTRYK8S_REGISTRY_TYPE={{ registryk8s_registry.type | default('docker') }}"
      - "ICR_REGISTRY_TYPE={{ icr_registry.type | default('docker') }}"
      - "K8S_REGISTRY_SECURE={{ k8s_registry.secure | default(True) }}"
      - "GCR_REGISTRY_SECURE={{ gcr_registry.secure | default(True) }}"
      - "QUAY_REGISTRY_SECURE={{ quay_registry.secure | default(True) }}"
      - "DOCKER_REGISTRY_SECURE={{ docker_registry.secure | default(True) }}"
      - "ELASTIC_REGISTRY_SECURE={{ elastic_registry.secure | default(True) }}"
      - "GHCR_REGISTRY_SECURE={{ ghcr_registry.secure | default(True) }}"
      - "REGISTRYK8S_REGISTRY_SECURE={{ registryk8s_registry.secure | default(True) }}"
      - "ICR_REGISTRY_SECURE={{ icr_registry.secure | default(True) }}"
      - "K8S_REGISTRY_ADDITIONAL_OVERRIDES={{ k8s_registry.additional_overrides | default('undef') }}"
      - "GCR_REGISTRY_ADDITIONAL_OVERRIDES={{ gcr_registry.additional_overrides | default('undef') }}"
      - "QUAY_REGISTRY_ADDITIONAL_OVERRIDES={{ quay_registry.additional_overrides | default('undef') }}"
      - "DOCKER_REGISTRY_ADDITIONAL_OVERRIDES={{ docker_registry.additional_overrides | default('undef') }}"
      - "ELASTIC_REGISTRY_ADDITIONAL_OVERRIDES={{ elastic_registry.additional_overrides | default('undef') }}"
      - "GHCR_REGISTRY_ADDITIONAL_OVERRIDES={{ ghcr_registry.additional_overrides | default('undef') }}"
      - "REGISTRYK8S_REGISTRY_ADDITIONAL_OVERRIDES={{ registryk8s_registry.additional_overrides | default('undef') }}"
      - "ICR_REGISTRY_ADDITIONAL_OVERRIDES={{ icr_registry.additional_overrides | default('undef') }}"
      - "USE_DEFAULT_REGISTRIES={{ use_default_registries }}"
      - "RECONFIGURE_ENDPOINTS={{ reconfigure_endpoints }}"
      - "INITIAL_DB_POPULATED={{ initial_db_populated }}"
      - "INCOMPLETE_BOOTSTRAP={{ incomplete_bootstrap }}"
      - "APISERVER_SANS={{ apiserver_cert_sans | join(',') }}"
      - "OIDC_ISSUER_URL={{ apiserver_oidc.issuer_url | default('undef') }}"
      - "OIDC_CLIENT_ID={{ apiserver_oidc.client_id | default('undef') }}"
      - "OIDC_USERNAME_CLAIM={{ apiserver_oidc.username_claim | default('undef') }}"
      - "OIDC_GROUPS_CLAIM={{ apiserver_oidc.groups_claim | default('undef') }}"
      - "KUBERNETES_VERSION={{ kubernetes_version }}"

  - name: Write simplex flag
    file:
      path: /etc/platform/simplex
      state: touch

  when: save_config_to_db and restore_mode|default(none) != 'optimized'
